#!/usr/bin/env python3
"""
AI Persona Training Data Generation System
ë‹¤ì–‘í•œ í˜ë¥´ì†Œë‚˜ë¡œ í•™ìŠµ ë°ì´í„°ë¥¼ ìë™ ìƒì„±í•˜ëŠ” ì‹œìŠ¤í…œ
"""

import json
import subprocess
from typing import Dict, List
import hashlib
import os
from datetime import datetime

class PersonaTrainingSystem:
    """
    ë‹¤ì–‘í•œ í˜ë¥´ì†Œë‚˜ì˜ AIë“¤ì´ ë™ì¼í•œ ë¬¸ì œë¥¼ ê°ìì˜ ê´€ì ìœ¼ë¡œ í•´ê²°
    â†’ ë‹¤ì–‘í•œ í•™ìŠµ ë°ì´í„° ìë™ ìƒì„±
    """
    
    def __init__(self):
        # í˜ë¥´ì†Œë‚˜ ì •ì˜ (ê° AIì˜ íŠ¹ì„±)
        self.personas = {
            "architect": {
                "ai": "claude",
                "prompt_style": "ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ì™€ ì„¤ê³„ íŒ¨í„´ ì¤‘ì‹¬",
                "focus": ["í™•ì¥ì„±", "ìœ ì§€ë³´ìˆ˜ì„±", "ì„¤ê³„ ì›ì¹™"]
            },
            "perfectionist": {
                "ai": "gemini", 
                "prompt_style": "ì™„ë²½í•œ ì½”ë“œ í’ˆì§ˆê³¼ ìµœì í™” ì¶”êµ¬",
                "focus": ["ì„±ëŠ¥", "ì½”ë“œ í’ˆì§ˆ", "ì—£ì§€ ì¼€ì´ìŠ¤"]
            },
            "pragmatist": {
                "ai": "codex",
                "prompt_style": "ì‹¤ìš©ì ì´ê³  ë¹ ë¥¸ í•´ê²°ì±… ì„ í˜¸",
                "focus": ["êµ¬í˜„ ì†ë„", "ì‹¤ìš©ì„±", "MVP"]
            },
            "innovator": {
                "ai": "claude",
                "prompt_style": "ì°½ì˜ì ì´ê³  í˜ì‹ ì ì¸ ì ‘ê·¼",
                "focus": ["ìƒˆë¡œìš´ ê¸°ìˆ ", "ì°½ì˜ì„±", "ë¯¸ë˜ ì§€í–¥"]
            },
            "educator": {
                "ai": "gemini",
                "prompt_style": "êµìœ¡ì ì´ê³  ì„¤ëª…ì´ ìƒì„¸í•¨",
                "focus": ["ì´í•´ë„", "ë¬¸ì„œí™”", "í•™ìŠµ ê³¡ì„ "]
            },
            "security_expert": {
                "ai": "codex",
                "prompt_style": "ë³´ì•ˆê³¼ ì•ˆì „ì„± ìµœìš°ì„ ",
                "focus": ["ë³´ì•ˆ", "ê²€ì¦", "ì·¨ì•½ì "]
            }
        }
        
        self.training_data_path = "training_data/"
        os.makedirs(self.training_data_path, exist_ok=True)
    
    def generate_training_data(self, problem: str, context: Dict = None):
        """
        í•˜ë‚˜ì˜ ë¬¸ì œë¥¼ ì—¬ëŸ¬ í˜ë¥´ì†Œë‚˜ë¡œ í•´ê²°í•˜ì—¬ í•™ìŠµ ë°ì´í„° ìƒì„±
        """
        
        problem_id = hashlib.md5(problem.encode()).hexdigest()[:8]
        dataset = {
            "problem_id": problem_id,
            "problem": problem,
            "context": context or {},
            "generated_at": datetime.now().isoformat(),
            "responses": {}
        }
        
        print(f"ğŸ¯ ë¬¸ì œ: {problem[:50]}...")
        print(f"ğŸ“Š {len(self.personas)}ê°œ í˜ë¥´ì†Œë‚˜ë¡œ ë°ì´í„° ìƒì„± ì¤‘...\n")
        
        # ê° í˜ë¥´ì†Œë‚˜ë³„ë¡œ ë³‘ë ¬ ì²˜ë¦¬
        processes = {}
        for persona_name, persona_config in self.personas.items():
            prompt = self._create_persona_prompt(persona_name, persona_config, problem)
            
            # AI ì‹¤í–‰
            cmd = f'{persona_config["ai"]} -p "{prompt}"'
            process = subprocess.Popen(
                cmd,
                shell=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            processes[persona_name] = process
            print(f"ğŸ¤– {persona_name}: ì‘ì—… ì‹œì‘...")
        
        # ê²°ê³¼ ìˆ˜ì§‘
        for persona_name, process in processes.items():
            stdout, stderr = process.communicate()
            dataset["responses"][persona_name] = {
                "output": stdout.strip(),
                "persona_config": self.personas[persona_name],
                "timestamp": datetime.now().isoformat()
            }
            print(f"âœ… {persona_name}: ì™„ë£Œ")
        
        # í•™ìŠµ ë°ì´í„° ì €ì¥
        filename = f"{self.training_data_path}data_{problem_id}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(dataset, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ í•™ìŠµ ë°ì´í„° ì €ì¥: {filename}")
        return dataset
    
    def _create_persona_prompt(self, persona_name: str, config: Dict, problem: str) -> str:
        """í˜ë¥´ì†Œë‚˜ë³„ ë§ì¶¤ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        return f"""ë‹¹ì‹ ì€ {persona_name} í˜ë¥´ì†Œë‚˜ì…ë‹ˆë‹¤.
ìŠ¤íƒ€ì¼: {config['prompt_style']}
ì¤‘ì  ì‚¬í•­: {', '.join(config['focus'])}

ë¬¸ì œ:
{problem}

ë‹¹ì‹ ì˜ í˜ë¥´ì†Œë‚˜ì— ë§ê²Œ í•´ê²°ì±…ì„ ì œì‹œí•˜ì„¸ìš”.
ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:

## ì ‘ê·¼ ë°©ì‹
[ë‹¹ì‹ ì˜ í˜ë¥´ì†Œë‚˜ ê´€ì ì—ì„œì˜ ì ‘ê·¼]

## í•´ê²°ì±…
[êµ¬ì²´ì ì¸ í•´ê²° ë°©ì•ˆ]

## ì½”ë“œ
```
[ì‹¤ì œ êµ¬í˜„ ì½”ë“œ]
```

## ê·¼ê±°
[ì™œ ì´ ë°©ì‹ì„ ì„ íƒí–ˆëŠ”ì§€]"""
    
    def create_fine_tuning_dataset(self, problems: List[str]):
        """
        ì—¬ëŸ¬ ë¬¸ì œë¡œ Fine-tuningìš© ë°ì´í„°ì…‹ ìƒì„±
        """
        all_data = []
        
        for i, problem in enumerate(problems, 1):
            print(f"\n{'='*50}")
            print(f"ë¬¸ì œ {i}/{len(problems)}")
            print(f"{'='*50}")
            
            dataset = self.generate_training_data(problem)
            all_data.append(dataset)
        
        # Fine-tuning í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        fine_tuning_data = self._convert_to_fine_tuning_format(all_data)
        
        # JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥
        output_file = f"{self.training_data_path}fine_tuning_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jsonl"
        with open(output_file, 'w', encoding='utf-8') as f:
            for item in fine_tuning_data:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')
        
        print(f"\nğŸ“ Fine-tuning ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ: {output_file}")
        print(f"ğŸ“Š ì´ {len(fine_tuning_data)}ê°œ í•™ìŠµ ìƒ˜í”Œ ìƒì„±")
        
        return output_file
    
    def _convert_to_fine_tuning_format(self, all_data: List[Dict]) -> List[Dict]:
        """
        ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ Fine-tuning í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        """
        fine_tuning_data = []
        
        for dataset in all_data:
            problem = dataset["problem"]
            
            # ê° í˜ë¥´ì†Œë‚˜ ì‘ë‹µì„ í•™ìŠµ ë°ì´í„°ë¡œ ë³€í™˜
            for persona_name, response in dataset["responses"].items():
                fine_tuning_data.append({
                    "messages": [
                        {
                            "role": "system",
                            "content": f"You are an AI with {persona_name} persona. {self.personas[persona_name]['prompt_style']}"
                        },
                        {
                            "role": "user",
                            "content": problem
                        },
                        {
                            "role": "assistant",
                            "content": response["output"]
                        }
                    ],
                    "metadata": {
                        "persona": persona_name,
                        "focus_areas": self.personas[persona_name]["focus"],
                        "problem_id": dataset["problem_id"]
                    }
                })
        
        return fine_tuning_data

class AutomatedLearningPipeline:
    """
    ìë™ í•™ìŠµ íŒŒì´í”„ë¼ì¸
    GitHub Issue â†’ Multi-Persona Solutions â†’ Training Data â†’ Model Fine-tuning
    """
    
    def __init__(self):
        self.training_system = PersonaTrainingSystem()
    
    def process_from_github(self, repo: str = "ihw33/ai-orchestra-v02"):
        """
        GitHub ì´ìŠˆë“¤ì„ í•™ìŠµ ë°ì´í„°ë¡œ ë³€í™˜
        """
        # ëª¨ë“  ì˜¤í”ˆ ì´ìŠˆ ê°€ì ¸ì˜¤ê¸°
        cmd = f"gh issue list -R {repo} --json number,title,body -q '.[]'"
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        issues = json.loads(result.stdout) if result.stdout else []
        
        problems = []
        for issue in issues:
            problem = f"Issue #{issue['number']}: {issue['title']}\n\n{issue['body']}"
            problems.append(problem)
        
        if problems:
            print(f"ğŸ“š {len(problems)}ê°œ ì´ìŠˆë¥¼ í•™ìŠµ ë°ì´í„°ë¡œ ë³€í™˜ ì¤‘...")
            return self.training_system.create_fine_tuning_dataset(problems)
        else:
            print("âš ï¸ ì²˜ë¦¬í•  ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # 1. ë‹¨ì¼ ë¬¸ì œë¡œ í…ŒìŠ¤íŠ¸
    system = PersonaTrainingSystem()
    
    test_problem = """
    React ì»´í¬ë„ŒíŠ¸ì—ì„œ ìƒíƒœ ê´€ë¦¬ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í•˜ëŠ” ë°©ë²•ì„ êµ¬í˜„í•˜ì„¸ìš”.
    ìš”êµ¬ì‚¬í•­:
    - TypeScript ì‚¬ìš©
    - ì„±ëŠ¥ ìµœì í™” ê³ ë ¤
    - í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•œ êµ¬ì¡°
    """
    
    # ë‹¤ì–‘í•œ í˜ë¥´ì†Œë‚˜ë¡œ í•´ê²°ì±… ìƒì„±
    dataset = system.generate_training_data(test_problem)
    
    # 2. GitHub ì´ìŠˆì—ì„œ ìë™ ìƒì„±
    # pipeline = AutomatedLearningPipeline()
    # pipeline.process_from_github()