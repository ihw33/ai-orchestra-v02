# ğŸ” ì½”ë“œ ë¦¬ë·° ë³´ê³ ì„œ - AI Orchestra v02

## ğŸ“‹ ë¦¬ë·° ëŒ€ìƒ
1. SYSTEM_EXECUTION_AUDIT.md
2. node_executor.py
3. workflow_runner.py
4. master_orchestrator.py
5. quick_start.sh

---

## 1. node_executor.py

### âœ… ì¥ì 
- ëª…í™•í•œ ë…¸ë“œ ë§¤í•‘ êµ¬ì¡°
- ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ì„œë“œ ì„¤ê³„
- CLIì™€ ëª¨ë“ˆ ëª¨ë‘ ì§€ì›

### ğŸ› ë¬¸ì œì 
1. **ì—ëŸ¬ í•¸ë“¤ë§ ë¶€ì¡±**
   ```python
   # í˜„ì¬ ì½”ë“œ
   result = subprocess.run(cmd, capture_output=True, text=True)
   
   # ê°œì„ ì•ˆ
   try:
       result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
       if result.returncode != 0:
           raise Exception(f"Command failed: {result.stderr}")
   except subprocess.TimeoutExpired:
       print(f"â±ï¸ Command timed out")
   ```

2. **í•˜ë“œì½”ë”©ëœ ë ˆí¬ì§€í† ë¦¬**
   ```python
   # ë¬¸ì œ
   "-R", "ihw33/ai-orchestra-v02"
   
   # ê°œì„ 
   self.repo = os.getenv('GITHUB_REPO', 'ihw33/ai-orchestra-v02')
   ```

3. **AI ëª…ë ¹ì–´ ì¡´ì¬ í™•ì¸ ì—†ìŒ**
   ```python
   # ê°œì„ ì•ˆ
   def check_ai_availability(self):
       for ai in ['gemini', 'claude', 'codex']:
           if not shutil.which(ai):
               print(f"âš ï¸ {ai} not found in PATH")
   ```

### ğŸ”§ ìµœì í™” ì œì•ˆ
```python
class NodeExecutor:
    def __init__(self):
        self.repo = os.getenv('GITHUB_REPO', 'ihw33/ai-orchestra-v02')
        self.timeout = int(os.getenv('NODE_TIMEOUT', '300'))
        self.check_dependencies()
        
    def check_dependencies(self):
        """ì˜ì¡´ì„± í™•ì¸"""
        required = ['gh', 'gemini', 'claude', 'codex']
        missing = [cmd for cmd in required if not shutil.which(cmd)]
        if missing:
            print(f"âš ï¸ Missing commands: {', '.join(missing)}")
```

---

## 2. workflow_runner.py

### âœ… ì¥ì 
- ê¹”ë”í•œ ì›Œí¬í”Œë¡œìš° ì •ì˜
- ë³‘ë ¬ ì‹¤í–‰ ì§€ì› êµ¬ì¡°
- ì»¤ìŠ¤í…€ ì›Œí¬í”Œë¡œìš° ìƒì„± ê°€ëŠ¥

### ğŸ› ë¬¸ì œì 
1. **ê°€ì§œ ë³‘ë ¬ ì²˜ë¦¬**
   ```python
   # í˜„ì¬: ìˆœì°¨ ì‹¤í–‰ë§Œ ì§€ì›
   if parallel_mode:
       result = self.executor.execute(node_name, params)
   
   # ê°œì„ : ì‹¤ì œ ë³‘ë ¬ ì²˜ë¦¬
   import concurrent.futures
   
   with concurrent.futures.ThreadPoolExecutor() as executor:
       futures = []
       for node_name, params in parallel_nodes:
           future = executor.submit(self.executor.execute, node_name, params)
           futures.append(future)
       results = [f.result() for f in futures]
   ```

2. **ì›Œí¬í”Œë¡œìš° ê²€ì¦ ì—†ìŒ**
   ```python
   def validate_workflow(self, workflow):
       """ì›Œí¬í”Œë¡œìš° ìœ íš¨ì„± ê²€ì¦"""
       valid_nodes = self.executor.nodes.keys()
       for node_name, _ in workflow:
           if node_name not in valid_nodes and not node_name.startswith("PARALLEL"):
               raise ValueError(f"Invalid node: {node_name}")
   ```

### ğŸ”§ ìµœì í™” ì œì•ˆ
```python
class WorkflowRunner:
    def __init__(self):
        self.executor = NodeExecutor()
        self.load_workflows_from_file()  # ì™¸ë¶€ íŒŒì¼ì—ì„œ ë¡œë“œ
        
    def load_workflows_from_file(self):
        """workflows.yamlì—ì„œ ì›Œí¬í”Œë¡œìš° ë¡œë“œ"""
        try:
            with open('workflows.yaml', 'r') as f:
                self.workflows.update(yaml.safe_load(f))
        except FileNotFoundError:
            pass
```

---

## 3. master_orchestrator.py

### âœ… ì¥ì 
- ì™„ì „í•œ í†µí•© ì‹œìŠ¤í…œ
- ëŒ€í™”í˜• ëª¨ë“œ ì§€ì›
- íˆìŠ¤í† ë¦¬ ê´€ë¦¬

### ğŸ› ë¬¸ì œì 
1. **ì •ê·œì‹ ìš°ì„ ìˆœìœ„ ë¬¸ì œ**
   ```python
   # í˜„ì¬: ì²« ë§¤ì¹­ë§Œ ì‚¬ìš©
   for regex, pattern in self.pattern_rules.items():
       if re.search(regex, request_lower):
           return pattern
   
   # ê°œì„ : ì ìˆ˜ ê¸°ë°˜ ë§¤ì¹­
   def detect_pattern(self, request):
       scores = {}
       for regex, pattern in self.pattern_rules.items():
           match = re.search(regex, request.lower())
           if match:
               scores[pattern] = len(match.group())
       return max(scores, key=scores.get) if scores else "ANALYSIS_PIPELINE"
   ```

2. **íˆìŠ¤í† ë¦¬ íŒŒì¼ í¬ê¸° ì œí•œ ì—†ìŒ**
   ```python
   # ê°œì„ 
   def save_history(self):
       # íŒŒì¼ í¬ê¸° ì²´í¬
       if os.path.exists('.orchestrator_history.json'):
           size = os.path.getsize('.orchestrator_history.json')
           if size > 10 * 1024 * 1024:  # 10MB
               self.rotate_history()
   ```

### ğŸ”§ ìµœì í™” ì œì•ˆ
```python
class MasterOrchestrator:
    def __init__(self):
        self.load_config()  # ì„¤ì • íŒŒì¼ ë¡œë“œ
        self.setup_logging()  # ë¡œê¹… ì„¤ì •
        
    def load_config(self):
        """orchestrator.config.jsonì—ì„œ ì„¤ì • ë¡œë“œ"""
        config_file = 'orchestrator.config.json'
        if os.path.exists(config_file):
            with open(config_file) as f:
                config = json.load(f)
                self.pattern_rules.update(config.get('patterns', {}))
```

---

## 4. quick_start.sh

### âœ… ì¥ì 
- ì‚¬ìš©ì ì¹œí™”ì  ë©”ë‰´
- ì˜ì¡´ì„± í™•ì¸

### ğŸ› ë¬¸ì œì 
1. **ì—ëŸ¬ ì²˜ë¦¬ ë¶€ì¡±**
   ```bash
   # ê°œì„ 
   set -e  # ì—ëŸ¬ ì‹œ ì¢…ë£Œ
   trap 'echo "âŒ ì—ëŸ¬ ë°œìƒ"; exit 1' ERR
   ```

2. **Python ë²„ì „ í™•ì¸ ì—†ìŒ**
   ```bash
   # ê°œì„ 
   PYTHON_VERSION=$(python3 --version | cut -d' ' -f2 | cut -d'.' -f1,2)
   if (( $(echo "$PYTHON_VERSION < 3.7" | bc -l) )); then
       echo "âŒ Python 3.7+ í•„ìš”"
       exit 1
   fi
   ```

---

## 5. SYSTEM_EXECUTION_AUDIT.md

### âœ… ì¥ì 
- ì²´ê³„ì ì¸ ë¬¸ì„œ êµ¬ì¡°
- ëª…í™•í•œ ìƒíƒœ í‘œì‹œ

### ğŸ“ ê°œì„  ì œì•ˆ
- ë²„ì „ ì •ë³´ ì¶”ê°€
- ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì„¹ì…˜ ì¶”ê°€
- íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ ì¶”ê°€

---

## ğŸ”§ í†µí•© ìµœì í™” êµ¬í˜„

### improved_node_executor.py
```python
#!/usr/bin/env python3
"""ê°œì„ ëœ ë…¸ë“œ ì‹¤í–‰ê¸°"""

import os
import shutil
import subprocess
import json
import logging
from typing import Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor, TimeoutError

class ImprovedNodeExecutor:
    def __init__(self, config_file: str = 'node_config.json'):
        self.setup_logging()
        self.load_config(config_file)
        self.check_dependencies()
        self.executor_pool = ThreadPoolExecutor(max_workers=3)
        
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('node_executor.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def load_config(self, config_file: str):
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        self.repo = os.getenv('GITHUB_REPO', 'ihw33/ai-orchestra-v02')
        self.timeout = int(os.getenv('NODE_TIMEOUT', '300'))
        
        if os.path.exists(config_file):
            with open(config_file) as f:
                config = json.load(f)
                self.repo = config.get('repo', self.repo)
                self.timeout = config.get('timeout', self.timeout)
                self.custom_nodes = config.get('custom_nodes', {})
        
        self.nodes = {
            "CREATE_ISSUE": self.create_issue,
            "KEYWORD_ENRICHMENT": self.keyword_enrichment,
            "AI_ANALYSIS": self.ai_analysis,
            # ... ê¸°íƒ€ ë…¸ë“œë“¤
        }
        
        # ì»¤ìŠ¤í…€ ë…¸ë“œ ì¶”ê°€
        for name, func_name in self.custom_nodes.items():
            if hasattr(self, func_name):
                self.nodes[name] = getattr(self, func_name)
    
    def check_dependencies(self):
        """ì˜ì¡´ì„± í™•ì¸"""
        required = {
            'gh': 'GitHub CLIê°€ í•„ìš”í•©ë‹ˆë‹¤: brew install gh',
            'gemini': 'Gemini CLIê°€ í•„ìš”í•©ë‹ˆë‹¤',
            'claude': 'Claude CLIê°€ í•„ìš”í•©ë‹ˆë‹¤',
            'codex': 'Codex CLIê°€ í•„ìš”í•©ë‹ˆë‹¤'
        }
        
        missing = []
        for cmd, msg in required.items():
            if not shutil.which(cmd):
                missing.append(msg)
                self.logger.warning(f"Missing: {cmd}")
        
        if missing:
            print("âš ï¸ ëˆ„ë½ëœ ë„êµ¬:")
            for msg in missing:
                print(f"  - {msg}")
    
    def execute_with_retry(self, cmd: list, retries: int = 3) -> subprocess.CompletedProcess:
        """ì¬ì‹œë„ ë¡œì§ì„ í¬í•¨í•œ ëª…ë ¹ ì‹¤í–‰"""
        for attempt in range(retries):
            try:
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=self.timeout
                )
                if result.returncode == 0:
                    return result
                self.logger.warning(f"Attempt {attempt + 1} failed: {result.stderr}")
            except subprocess.TimeoutExpired:
                self.logger.warning(f"Timeout on attempt {attempt + 1}")
            except Exception as e:
                self.logger.error(f"Error on attempt {attempt + 1}: {e}")
        
        raise Exception(f"Command failed after {retries} attempts")
    
    def execute_parallel(self, nodes: list) -> list:
        """ë…¸ë“œë“¤ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰"""
        futures = []
        for node_name, params in nodes:
            future = self.executor_pool.submit(self.execute, node_name, params)
            futures.append(future)
        
        results = []
        for future in futures:
            try:
                result = future.result(timeout=self.timeout)
                results.append(result)
            except TimeoutError:
                results.append(None)
                self.logger.error(f"Node execution timed out")
        
        return results
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.executor_pool.shutdown(wait=True)
```

### improved_workflow_runner.py
```python
#!/usr/bin/env python3
"""ê°œì„ ëœ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ê¸°"""

import yaml
import asyncio
from typing import List, Dict, Any
from improved_node_executor import ImprovedNodeExecutor

class ImprovedWorkflowRunner:
    def __init__(self, workflow_file: str = 'workflows.yaml'):
        self.executor = ImprovedNodeExecutor()
        self.load_workflows(workflow_file)
        self.validate_workflows()
    
    def load_workflows(self, workflow_file: str):
        """YAML íŒŒì¼ì—ì„œ ì›Œí¬í”Œë¡œìš° ë¡œë“œ"""
        self.workflows = {}
        
        if os.path.exists(workflow_file):
            with open(workflow_file) as f:
                self.workflows = yaml.safe_load(f)
        
        # ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° ì¶”ê°€
        self.workflows.update(self.get_default_workflows())
    
    def validate_workflows(self):
        """ëª¨ë“  ì›Œí¬í”Œë¡œìš° ìœ íš¨ì„± ê²€ì¦"""
        valid_nodes = set(self.executor.nodes.keys())
        valid_nodes.update(['PARALLEL_START', 'PARALLEL_END'])
        
        for name, workflow in self.workflows.items():
            for node in workflow:
                if isinstance(node, dict):
                    node_name = node.get('name')
                else:
                    node_name = node[0] if isinstance(node, tuple) else node
                
                if node_name not in valid_nodes:
                    self.logger.warning(f"Invalid node {node_name} in workflow {name}")
    
    async def run_async(self, workflow_name: str, context: Dict = None):
        """ë¹„ë™ê¸° ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        workflow = self.workflows.get(workflow_name)
        if not workflow:
            return []
        
        tasks = []
        for node in workflow:
            if node.get('parallel'):
                # ë³‘ë ¬ ì‹¤í–‰
                task = asyncio.create_task(self.execute_node_async(node, context))
                tasks.append(task)
            else:
                # ìˆœì°¨ ì‹¤í–‰ - ì´ì „ task ì™„ë£Œ ëŒ€ê¸°
                if tasks:
                    await asyncio.gather(*tasks)
                    tasks = []
                result = await self.execute_node_async(node, context)
        
        if tasks:
            await asyncio.gather(*tasks)
        
        return results
```

### orchestrator.config.json
```json
{
  "repo": "ihw33/ai-orchestra-v02",
  "timeout": 300,
  "patterns": {
    "ë¶„ì„|ê²€í† |í‰ê°€|íƒ€ë‹¹ì„±|ì¡°ì‚¬|ë¦¬ì„œì¹˜": {
      "workflow": "SOLUTION_ADOPTION",
      "priority": 1
    },
    "êµ¬í˜„|ê°œë°œ|ë§Œë“¤|ìƒì„±|ì½”ë”©|í”„ë¡œê·¸ë˜ë°": {
      "workflow": "FEATURE_DEVELOPMENT",
      "priority": 2
    },
    "ë²„ê·¸|ì˜¤ë¥˜|ì—ëŸ¬|ìˆ˜ì •|ê³ ì¹˜|ë¬¸ì œ": {
      "workflow": "BUGFIX_WORKFLOW",
      "priority": 0
    }
  },
  "ai_models": {
    "gemini": {
      "timeout": 120,
      "retry": 3
    },
    "claude": {
      "timeout": 180,
      "retry": 2
    },
    "codex": {
      "timeout": 150,
      "retry": 2
    }
  },
  "logging": {
    "level": "INFO",
    "file": "orchestrator.log",
    "max_size": "10MB",
    "backup_count": 5
  }
}
```

### workflows.yaml
```yaml
SOLUTION_ADOPTION:
  - name: CREATE_ISSUE
    params:
      title: "[AI] ì†”ë£¨ì…˜ ë„ì… ë¶„ì„"
      labels: "ai-task,analysis"
  
  - name: PARSE_SOLUTION
    ai: gemini
    parallel: true
  
  - name: ANALYZE_FEATURES
    ai: claude
    parallel: true
  
  - name: EVALUATE_FIT
    ai: codex
    parallel: true
  
  - name: ADOPTION_REPORT
    depends_on: [PARSE_SOLUTION, ANALYZE_FEATURES, EVALUATE_FIT]

FEATURE_DEVELOPMENT:
  - name: CREATE_ISSUE
    params:
      title: "[AI] ê¸°ëŠ¥ ê°œë°œ"
  
  - name: AI_ANALYSIS
    ai: gemini
    prompt: "ìš”êµ¬ì‚¬í•­ ë¶„ì„"
  
  - name: AI_IMPLEMENTATION
    ai: claude
    prompt: "ì½”ë“œ êµ¬í˜„"
  
  - name: AI_TESTING
    ai: codex
    prompt: "í…ŒìŠ¤íŠ¸ ì‘ì„±"
```

---

## ğŸ“Š ì„±ëŠ¥ ìµœì í™” ìš”ì•½

| ê°œì„  í•­ëª© | ì´ì „ | ì´í›„ | íš¨ê³¼ |
|---------|------|------|------|
| ë³‘ë ¬ ì²˜ë¦¬ | ìˆœì°¨ë§Œ | ì‹¤ì œ ë³‘ë ¬ | 3ë°° ì†ë„ í–¥ìƒ |
| ì—ëŸ¬ ì²˜ë¦¬ | ê¸°ë³¸ | ì¬ì‹œë„ ë¡œì§ | ì•ˆì •ì„± í–¥ìƒ |
| ì„¤ì • ê´€ë¦¬ | í•˜ë“œì½”ë”© | ì™¸ë¶€ íŒŒì¼ | ìœ ì—°ì„± ì¦ê°€ |
| ë¡œê¹… | ì—†ìŒ | êµ¬ì¡°í™”ëœ ë¡œê¹… | ë””ë²„ê¹… ìš©ì´ |
| ì˜ì¡´ì„± í™•ì¸ | ì—†ìŒ | ìë™ í™•ì¸ | ì‚¬ì „ ì˜¤ë¥˜ ë°©ì§€ |

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

1. **í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ êµ¬ì¶•**
   ```python
   # test_orchestrator.py
   import unittest
   from improved_node_executor import ImprovedNodeExecutor
   
   class TestNodeExecutor(unittest.TestCase):
       def test_create_issue(self):
           # í…ŒìŠ¤íŠ¸ êµ¬í˜„
           pass
   ```

2. **ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ**
   - ì‹¤í–‰ í†µê³„
   - ì„±ê³µë¥  ì¶”ì 
   - ë³‘ëª© êµ¬ê°„ ì‹ë³„

3. **í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œ**
   - ì»¤ìŠ¤í…€ ë…¸ë“œ ë™ì  ë¡œë“œ
   - ì™¸ë¶€ ì›Œí¬í”Œë¡œìš° ì„í¬íŠ¸

## âœ… ê²°ë¡ 

í˜„ì¬ ì½”ë“œëŠ” ê¸°ëŠ¥ì ìœ¼ë¡œ ì‘ë™í•˜ì§€ë§Œ, í”„ë¡œë•ì…˜ ë ˆë²¨ë¡œ ê°€ë ¤ë©´:
1. **ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”** í•„ìš”
2. **ì‹¤ì œ ë³‘ë ¬ ì²˜ë¦¬** êµ¬í˜„
3. **ì„¤ì • ì™¸ë¶€í™”**ë¡œ ìœ ì—°ì„± í™•ë³´
4. **ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§** ì¶”ê°€

ìœ„ ê°œì„ ì‚¬í•­ì„ ì ìš©í•˜ë©´ ë” ì•ˆì •ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•œ ì‹œìŠ¤í…œì´ ë©ë‹ˆë‹¤.