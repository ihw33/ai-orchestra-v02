#!/usr/bin/env python3
"""
Metrics System - ê²½ëŸ‰ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ë¶„ì„
"""

import json
import time
from datetime import datetime
from typing import Dict, List, Optional
from dataclasses import dataclass, asdict
import os

@dataclass
class NodeMetric:
    """ë…¸ë“œ ì‹¤í–‰ ë©”íŠ¸ë¦­"""
    timestamp: str
    node_type: str
    executor: str
    success: bool
    duration: float
    issue_number: str = ""  # GitHub ì´ìŠˆ ë²ˆí˜¸ ì¶”ê°€
    error: str = ""

@dataclass
class ProcessMetric:
    """í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ë©”íŠ¸ë¦­"""
    timestamp: str
    process_name: str
    nodes_count: int
    total_duration: float
    success: bool
    issue_number: str = ""  # GitHub ì´ìŠˆ ë²ˆí˜¸ ì¶”ê°€
    nodes_used: List[str] = None

class MetricsCollector:
    """ê²½ëŸ‰ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, metrics_file: str = "metrics_lite.jsonl"):
        self.metrics_file = metrics_file
        self.active_processes = {}  # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤
        
        # íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒì„±
        if not os.path.exists(self.metrics_file):
            open(self.metrics_file, 'a').close()
    
    def record_node(self, node_type: str, executor: str, success: bool, duration: float, issue_number: str = "", error: str = ""):
        """ë…¸ë“œ ì‹¤í–‰ ê¸°ë¡"""
        metric = NodeMetric(
            timestamp=datetime.now().isoformat(),
            node_type=node_type,
            executor=executor,
            success=success,
            duration=duration,
            issue_number=issue_number,
            error=error
        )
        
        self._write_metric(asdict(metric))
    
    def record_process(self, process_name: str, nodes_count: int, duration: float, success: bool, nodes_used: List[str], issue_number: str = ""):
        """í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ê¸°ë¡"""
        metric = ProcessMetric(
            timestamp=datetime.now().isoformat(),
            process_name=process_name,
            nodes_count=nodes_count,
            total_duration=duration,
            success=success,
            issue_number=issue_number,
            nodes_used=nodes_used
        )
        
        self._write_metric(asdict(metric))
    
    def start_process(self, process_id: str):
        """í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ê¸°ë¡"""
        self.active_processes[process_id] = {
            "start_time": time.time(),
            "nodes": []
        }
    
    def end_process(self, process_id: str, success: bool):
        """í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ê¸°ë¡"""
        if process_id in self.active_processes:
            process_data = self.active_processes[process_id]
            duration = time.time() - process_data["start_time"]
            
            self.record_process(
                process_name=process_id,
                nodes_count=len(process_data["nodes"]),
                duration=duration,
                success=success,
                nodes_used=process_data["nodes"]
            )
            
            del self.active_processes[process_id]
    
    def _write_metric(self, metric: Dict):
        """ë©”íŠ¸ë¦­ì„ íŒŒì¼ì— ê¸°ë¡"""
        with open(self.metrics_file, 'a') as f:
            f.write(json.dumps(metric) + '\n')
    
    def analyze_patterns(self, days: int = 30) -> Dict:
        """íŒ¨í„´ ë¶„ì„"""
        node_stats = {}
        process_stats = {}
        executor_stats = {}
        
        # íŒŒì¼ ì½ê¸° (ìŠ¤íŠ¸ë¦¬ë°)
        with open(self.metrics_file, 'r') as f:
            for line in f:
                if not line.strip():
                    continue
                    
                try:
                    record = json.loads(line)
                    
                    # ë…¸ë“œ ë©”íŠ¸ë¦­
                    if 'node_type' in record:
                        node = record['node_type']
                        if node not in node_stats:
                            node_stats[node] = {
                                'count': 0,
                                'success': 0,
                                'total_time': 0,
                                'errors': []
                            }
                        
                        node_stats[node]['count'] += 1
                        if record['success']:
                            node_stats[node]['success'] += 1
                        node_stats[node]['total_time'] += record['duration']
                        if record.get('error'):
                            node_stats[node]['errors'].append(record['error'])
                        
                        # ì‹¤í–‰ìë³„ í†µê³„
                        executor = record.get('executor', 'unknown')
                        if executor not in executor_stats:
                            executor_stats[executor] = {
                                'count': 0,
                                'success': 0,
                                'total_time': 0
                            }
                        
                        executor_stats[executor]['count'] += 1
                        if record['success']:
                            executor_stats[executor]['success'] += 1
                        executor_stats[executor]['total_time'] += record['duration']
                    
                    # í”„ë¡œì„¸ìŠ¤ ë©”íŠ¸ë¦­
                    elif 'process_name' in record:
                        process = record['process_name']
                        if process not in process_stats:
                            process_stats[process] = {
                                'count': 0,
                                'success': 0,
                                'total_time': 0
                            }
                        
                        process_stats[process]['count'] += 1
                        if record['success']:
                            process_stats[process]['success'] += 1
                        process_stats[process]['total_time'] += record['total_duration']
                
                except json.JSONDecodeError:
                    continue
        
        return {
            'nodes': node_stats,
            'processes': process_stats,
            'executors': executor_stats
        }
    
    def generate_report(self) -> str:
        """ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        analysis = self.analyze_patterns()
        
        report = []
        report.append("=" * 60)
        report.append("ğŸ“Š AI Orchestra ë©”íŠ¸ë¦­ ë¦¬í¬íŠ¸")
        report.append("=" * 60)
        
        # Top 10 ë…¸ë“œ
        report.append("\nğŸ† Top 10 Most Used Nodes:")
        sorted_nodes = sorted(
            analysis['nodes'].items(),
            key=lambda x: x[1]['count'],
            reverse=True
        )[:10]
        
        for i, (node, stats) in enumerate(sorted_nodes, 1):
            if stats['count'] > 0:
                avg_time = stats['total_time'] / stats['count']
                success_rate = (stats['success'] / stats['count']) * 100
                
                status = "âœ…" if success_rate >= 90 else "âš ï¸" if success_rate >= 70 else "âŒ"
                report.append(f"  {i}. {node}: {stats['count']}íšŒ, {avg_time:.1f}ì´ˆ, {success_rate:.1f}% {status}")
        
        # ì‹¤í–‰ìë³„ ì„±ê³¼
        report.append("\nğŸ¤– AI Executor Performance:")
        for executor, stats in analysis['executors'].items():
            if stats['count'] > 0:
                avg_time = stats['total_time'] / stats['count']
                success_rate = (stats['success'] / stats['count']) * 100
                report.append(f"  {executor}: {stats['count']}íšŒ, {avg_time:.1f}ì´ˆ, {success_rate:.1f}%")
        
        # í”„ë¡œì„¸ìŠ¤ í†µê³„
        report.append("\nğŸ“‹ Process Statistics:")
        for process, stats in analysis['processes'].items():
            if stats['count'] > 0:
                avg_time = stats['total_time'] / stats['count']
                success_rate = (stats['success'] / stats['count']) * 100
                report.append(f"  {process}: {stats['count']}íšŒ, {avg_time:.1f}ì´ˆ, {success_rate:.1f}%")
        
        # ê°œì„  í•„ìš” ì‚¬í•­
        report.append("\nâš ï¸ ì£¼ì˜ í•„ìš”:")
        for node, stats in analysis['nodes'].items():
            if stats['count'] > 0:
                success_rate = (stats['success'] / stats['count']) * 100
                if success_rate < 80:
                    report.append(f"  - {node}: ì„±ê³µë¥  ë‚®ìŒ ({success_rate:.1f}%)")
                
                avg_time = stats['total_time'] / stats['count']
                if avg_time > 30:
                    report.append(f"  - {node}: ì‹¤í–‰ ì‹œê°„ ê¹€ ({avg_time:.1f}ì´ˆ)")
        
        # ìë™í™” ê°€ëŠ¥ íŒ¨í„´
        report.append("\nğŸ’¡ ìë™í™” ê°€ëŠ¥ íŒ¨í„´:")
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œë§Œ
        report.append("  - CREATE_ISSUE â†’ ADD_COMMENT íŒ¨í„´ ìì£¼ ë°œìƒ")
        report.append("  - TEST â†’ FIX â†’ TEST ë°˜ë³µ íŒ¨í„´ ê°ì§€")
        
        return "\n".join(report)
    
    def get_best_executor_for_node(self, node_type: str) -> Optional[str]:
        """ë…¸ë“œë³„ ìµœì  ì‹¤í–‰ì ì°¾ê¸°"""
        analysis = self.analyze_patterns()
        
        best_executor = None
        best_success_rate = 0
        
        # ê° ì‹¤í–‰ìë³„ë¡œ í•´ë‹¹ ë…¸ë“œ ì„±ê³µë¥  ê³„ì‚°
        for line in open(self.metrics_file, 'r'):
            try:
                record = json.loads(line)
                if record.get('node_type') == node_type:
                    # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ê³„ì‚° í•„ìš”
                    pass
            except:
                continue
        
        # ê°„ë‹¨í•œ ê¸°ë³¸ê°’ ë°˜í™˜
        default_mapping = {
            "analyze_code": "claude",
            "write_function": "codex",
            "run_test": "gemini"
        }
        
        return default_mapping.get(node_type, "claude")

class DashboardRenderer:
    """ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ ë Œë”ë§"""
    
    def __init__(self, metrics: MetricsCollector):
        self.metrics = metrics
    
    def render(self) -> str:
        """ì½˜ì†” ëŒ€ì‹œë³´ë“œ ë Œë”ë§"""
        analysis = self.metrics.analyze_patterns()
        
        # ì˜¤ëŠ˜ í†µê³„ ê³„ì‚° (ì‹¤ì œë¡œëŠ” ì‹œê°„ í•„í„°ë§ í•„ìš”)
        today_nodes = 0
        today_success = 0
        
        for stats in analysis['nodes'].values():
            today_nodes += stats['count']
            today_success += stats['success']
        
        success_rate = (today_success / today_nodes * 100) if today_nodes > 0 else 0
        
        dashboard = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           AI Orchestra KPI Dashboard                     â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ ğŸ“Š ì˜¤ëŠ˜ì˜ ì„±ê³¼                                            â•‘
â•‘ â€¢ ì²˜ë¦¬ ë…¸ë“œ: {today_nodes}ê°œ                              â•‘
â•‘ â€¢ ì„±ê³µë¥ : {success_rate:.1f}% {"âœ…" if success_rate >= 90 else "âš ï¸"}
â•‘                                                          â•‘
â•‘ ğŸ¯ ë…¸ë“œë³„ ì„±ê³¼ (Top 5)                                   â•‘"""
        
        # Top 5 ë…¸ë“œ
        sorted_nodes = sorted(
            analysis['nodes'].items(),
            key=lambda x: x[1]['count'],
            reverse=True
        )[:5]
        
        for i, (node, stats) in enumerate(sorted_nodes, 1):
            if stats['count'] > 0:
                sr = (stats['success'] / stats['count']) * 100
                dashboard += f"""
â•‘ {i}. {node[:20]:<20} {sr:>5.1f}% ({stats['count']}íšŒ)    â•‘"""
        
        dashboard += """
â•‘                                                          â•‘
â•‘ ğŸ¤– AI ì‹¤í–‰ì ì„±ê³¼                                        â•‘"""
        
        for executor, stats in analysis['executors'].items():
            if stats['count'] > 0:
                sr = (stats['success'] / stats['count']) * 100
                avg_time = stats['total_time'] / stats['count']
                dashboard += f"""
â•‘ â€¢ {executor:<10} {sr:>5.1f}% í‰ê·  {avg_time:>5.1f}ì´ˆ      â•‘"""
        
        dashboard += """
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """
        
        return dashboard

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
    metrics = MetricsCollector()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ê¸°ë¡
    print("=== í…ŒìŠ¤íŠ¸ ë©”íŠ¸ë¦­ ê¸°ë¡ ===")
    
    # ë…¸ë“œ ì‹¤í–‰ ê¸°ë¡
    metrics.record_node("create_issue", "claude", True, 3.2)
    metrics.record_node("write_function", "codex", True, 15.7)
    metrics.record_node("fix_bug_line", "codex", False, 8.9, "Syntax error")
    metrics.record_node("run_test", "gemini", True, 5.3)
    
    # í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ê¸°ë¡
    metrics.start_process("bug_fix_001")
    time.sleep(0.1)  # ì‹œë®¬ë ˆì´ì…˜
    metrics.end_process("bug_fix_001", True)
    
    # ë¦¬í¬íŠ¸ ìƒì„±
    print("\n=== ë©”íŠ¸ë¦­ ë¦¬í¬íŠ¸ ===")
    report = metrics.generate_report()
    print(report)
    
    # ëŒ€ì‹œë³´ë“œ ë Œë”ë§
    print("\n=== ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ ===")
    dashboard = DashboardRenderer(metrics)
    print(dashboard.render())