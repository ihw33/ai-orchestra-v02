#!/usr/bin/env python3
"""
AI Orchestra íŒ€ì›ë³„ KPI ì¶”ì  ì‹œìŠ¤í…œ
ê° AIì˜ ì„±ê³¼ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§
"""
import json
import subprocess
from datetime import datetime, timedelta
from typing import Dict, List

class TeamKPITracker:
    def __init__(self):
        self.kpi_data = {
            "Gemini": {
                "role": "Frontend/UI Lead",
                "kpis": {
                    "response_time": [],  # ì‘ë‹µ ì‹œê°„
                    "task_completion": 0,  # ì™„ë£Œí•œ ì‘ì—… ìˆ˜
                    "error_rate": 0,      # ì—ëŸ¬ìœ¨
                    "quality_score": 0,   # í’ˆì§ˆ ì ìˆ˜
                    "availability": 100   # ê°€ìš©ì„± %
                }
            },
            "Codex": {
                "role": "Backend Engineer",
                "kpis": {
                    "response_time": [],
                    "task_completion": 0,
                    "error_rate": 0,
                    "code_quality": 0,    # ì½”ë“œ í’ˆì§ˆ
                    "availability": 100
                }
            },
            "Claude": {
                "role": "PM & QA",
                "kpis": {
                    "response_time": [],
                    "task_completion": 0,
                    "review_count": 0,    # ë¦¬ë·° ìˆ˜
                    "issue_detection": 0, # ë°œê²¬í•œ ì´ìŠˆ
                    "availability": 100
                }
            },
            "Cursor": {
                "role": "Architect",
                "kpis": {
                    "response_time": [],
                    "task_completion": 0,
                    "design_quality": 0,  # ì„¤ê³„ í’ˆì§ˆ
                    "documentation": 0,   # ë¬¸ì„œí™”
                    "availability": 100
                }
            }
        }
        self.start_time = datetime.now()
        
    def measure_response_time(self, ai_name: str, question: str) -> float:
        """AI ì‘ë‹µ ì‹œê°„ ì¸¡ì •"""
        start = datetime.now()
        
        try:
            if ai_name == "Gemini":
                cmd = f"echo '{question}' | gemini 2>/dev/null | head -1"
                result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=10)
            elif ai_name == "Codex":
                cmd = f"echo '{question}' | codex exec 2>&1 | grep -A 2 '] codex' | tail -1"
                result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=15)
            elif ai_name == "Claude":
                result = subprocess.run(["claude", "--version"], capture_output=True, text=True, timeout=5)
            else:
                return -1
                
            response_time = (datetime.now() - start).total_seconds()
            
            # KPI ì—…ë°ì´íŠ¸
            if ai_name in self.kpi_data:
                self.kpi_data[ai_name]["kpis"]["response_time"].append(response_time)
                # ìµœê·¼ 10ê°œë§Œ ìœ ì§€
                if len(self.kpi_data[ai_name]["kpis"]["response_time"]) > 10:
                    self.kpi_data[ai_name]["kpis"]["response_time"].pop(0)
                    
            return response_time
            
        except subprocess.TimeoutExpired:
            # íƒ€ì„ì•„ì›ƒì€ ê°€ìš©ì„± ê°ì†Œ
            if ai_name in self.kpi_data:
                self.kpi_data[ai_name]["kpis"]["availability"] -= 5
            return -1
        except Exception as e:
            # ì—ëŸ¬ëŠ” ì—ëŸ¬ìœ¨ ì¦ê°€
            if ai_name in self.kpi_data:
                self.kpi_data[ai_name]["kpis"]["error_rate"] += 1
            return -1
    
    def update_task_completion(self, ai_name: str, completed: bool = True):
        """ì‘ì—… ì™„ë£Œ ì—…ë°ì´íŠ¸"""
        if ai_name in self.kpi_data and completed:
            self.kpi_data[ai_name]["kpis"]["task_completion"] += 1
    
    def calculate_performance_score(self, ai_name: str) -> float:
        """ì¢…í•© ì„±ê³¼ ì ìˆ˜ ê³„ì‚° (100ì  ë§Œì )"""
        if ai_name not in self.kpi_data:
            return 0
            
        kpis = self.kpi_data[ai_name]["kpis"]
        score = 0
        
        # 1. ê°€ìš©ì„± (30ì )
        score += kpis["availability"] * 0.3
        
        # 2. ì‘ë‹µ ì‹œê°„ (20ì ) - í‰ê·  3ì´ˆ ì´í•˜ë©´ ë§Œì 
        if kpis["response_time"]:
            avg_response = sum(kpis["response_time"]) / len(kpis["response_time"])
            response_score = max(0, 20 - (avg_response - 3) * 4)
            score += response_score
        else:
            score += 10  # ë°ì´í„° ì—†ìœ¼ë©´ ê¸°ë³¸ ì ìˆ˜
            
        # 3. ì‘ì—… ì™„ë£Œ (30ì ) - 10ê°œ ì™„ë£Œì‹œ ë§Œì 
        completion_score = min(30, kpis["task_completion"] * 3)
        score += completion_score
        
        # 4. ì—ëŸ¬ìœ¨ (20ì ) - ì—ëŸ¬ ì—†ìœ¼ë©´ ë§Œì 
        error_rate = kpis.get("error_rate", 0)
        error_score = max(0, 20 - error_rate * 5)
        score += error_score
        
        return round(score, 1)
    
    def generate_kpi_report(self) -> Dict:
        """KPI ë¦¬í¬íŠ¸ ìƒì„±"""
        report = {
            "timestamp": datetime.now().isoformat(),
            "uptime_minutes": (datetime.now() - self.start_time).seconds // 60,
            "team_performance": {}
        }
        
        for ai_name, data in self.kpi_data.items():
            avg_response = 0
            if data["kpis"]["response_time"]:
                avg_response = sum(data["kpis"]["response_time"]) / len(data["kpis"]["response_time"])
                
            report["team_performance"][ai_name] = {
                "role": data["role"],
                "performance_score": self.calculate_performance_score(ai_name),
                "metrics": {
                    "avg_response_time": round(avg_response, 2),
                    "tasks_completed": data["kpis"]["task_completion"],
                    "error_count": data["kpis"].get("error_rate", 0),
                    "availability": f"{data['kpis']['availability']}%"
                }
            }
        
        # íŒ€ í‰ê·  ì ìˆ˜
        scores = [self.calculate_performance_score(ai) for ai in self.kpi_data.keys()]
        report["team_average_score"] = round(sum(scores) / len(scores), 1)
        
        return report
    
    def print_kpi_dashboard(self):
        """KPI ëŒ€ì‹œë³´ë“œ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ“Š AI Orchestra Team KPI Dashboard")
        print("="*60)
        
        report = self.generate_kpi_report()
        
        # íŒ€ ì „ì²´ ì„±ê³¼
        print(f"\nğŸ¯ íŒ€ í‰ê·  ì„±ê³¼: {report['team_average_score']}/100")
        print(f"â±ï¸ ìš´ì˜ ì‹œê°„: {report['uptime_minutes']}ë¶„")
        
        # ê°œë³„ AI ì„±ê³¼
        print("\nğŸ“ˆ íŒ€ì›ë³„ KPI:")
        print("-"*60)
        
        for ai_name, perf in report["team_performance"].items():
            score = perf["performance_score"]
            
            # ì„±ê³¼ì— ë”°ë¥¸ ì´ëª¨ì§€
            if score >= 80:
                emoji = "ğŸŒŸ"
            elif score >= 60:
                emoji = "âœ…"
            elif score >= 40:
                emoji = "âš ï¸"
            else:
                emoji = "âŒ"
                
            print(f"\n{emoji} {ai_name} ({perf['role']})")
            print(f"  ì„±ê³¼ ì ìˆ˜: {score}/100")
            print(f"  í‰ê·  ì‘ë‹µ: {perf['metrics']['avg_response_time']}ì´ˆ")
            print(f"  ì™„ë£Œ ì‘ì—…: {perf['metrics']['tasks_completed']}ê°œ")
            print(f"  ì—ëŸ¬ íšŸìˆ˜: {perf['metrics']['error_count']}íšŒ")
            print(f"  ê°€ìš©ì„±: {perf['metrics']['availability']}")
        
        # ê°œì„  ì œì•ˆ
        print("\nğŸ’¡ ê°œì„  ì œì•ˆ:")
        for ai_name, perf in report["team_performance"].items():
            score = perf["performance_score"]
            if score < 60:
                print(f"  â€¢ {ai_name}: ì„±ê³¼ ê°œì„  í•„ìš” (í˜„ì¬ {score}ì )")
            if perf["metrics"]["avg_response_time"] > 5:
                print(f"  â€¢ {ai_name}: ì‘ë‹µ ì‹œê°„ ê°œì„  í•„ìš” ({perf['metrics']['avg_response_time']}ì´ˆ)")
            if perf["metrics"]["error_count"] > 3:
                print(f"  â€¢ {ai_name}: ì—ëŸ¬ìœ¨ ë†’ìŒ ({perf['metrics']['error_count']}íšŒ)")
    
    def save_kpi_report(self, filename="team_kpi_report.json"):
        """KPI ë¦¬í¬íŠ¸ ì €ì¥"""
        report = self.generate_kpi_report()
        with open(filename, "w") as f:
            json.dump(report, f, indent=2)
        return filename

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Team KPI Tracker ì‹œì‘...")
    
    tracker = TeamKPITracker()
    
    # í…ŒìŠ¤íŠ¸ ì¸¡ì •
    test_questions = [
        ("Gemini", "What is 1+1?"),
        ("Codex", "What is 2+2?"),
        ("Claude", "version check"),
        ("Gemini", "Hello?"),
    ]
    
    print("\nâ±ï¸ ì‘ë‹µ ì‹œê°„ ì¸¡ì • ì¤‘...")
    for ai_name, question in test_questions:
        response_time = tracker.measure_response_time(ai_name, question)
        if response_time > 0:
            print(f"  {ai_name}: {response_time:.2f}ì´ˆ")
            tracker.update_task_completion(ai_name, True)
        else:
            print(f"  {ai_name}: ì‘ë‹µ ì‹¤íŒ¨")
    
    # KPI ëŒ€ì‹œë³´ë“œ í‘œì‹œ
    tracker.print_kpi_dashboard()
    
    # ë¦¬í¬íŠ¸ ì €ì¥
    report_file = tracker.save_kpi_report()
    print(f"\nğŸ’¾ KPI ë¦¬í¬íŠ¸ ì €ì¥ë¨: {report_file}")

if __name__ == "__main__":
    main()